{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import argparse\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras import losses\n",
    "from tqdm import tqdm\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from keras.optimizers import Adadelta\n",
    "from sklearn.metrics.pairwise import paired_distances as dist\n",
    "# from Hyper import imgDraw, listClassification, resnet99_avg_recon\n",
    "from Hyper import imgDraw\n",
    "import libmr\n",
    "import numpy as np\n",
    "import rscls\n",
    "import glob\n",
    "from scipy import io\n",
    "from copy import deepcopy\n",
    "import time\n",
    "\n",
    "# new\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "# from keras.utils import to_categorical\n",
    "from Hypertorch import ResNet99\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import time\n",
    "from utils import to_categorical\n",
    "from torch.optim.lr_scheduler import LambdaLR   # 引入学习率调度的工具LambdaLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义学习率调整函数\n",
    "def lr_lambda(epoch):\n",
    "    return 1.0 if epoch < 270 else 0.1\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, lidar_data, labels):\n",
    "        self.data = data\n",
    "        self.lidar_data = lidar_data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_sample = self.data[idx]\n",
    "        lidar_sample = self.lidar_data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return data_sample, lidar_sample, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置args\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "parser = argparse.ArgumentParser(description='manual to this script')\n",
    "parser.add_argument('--numTrain', type=int, default=20)\n",
    "parser.add_argument('--dataset', type=str, default='data/Trento/trento_im.npy') \n",
    "# parser.add_argument('--dataset', type=str, default='data/Houston/houston_im.npy') \n",
    "parser.add_argument('--gt', type=str, default='data/Trento/trento_raw_gt.npy')\n",
    "# parser.add_argument('--gt', type=str, default='data/Houston/houston_raw_gt.npy')\n",
    "parser.add_argument('--num_epochs1', type=int, default=270) \n",
    "parser.add_argument('--num_epochs2', type=int, default=230) \n",
    "parser.add_argument('--batch_size', type=int, default=16) \n",
    "parser.add_argument('--output', type=str, default='output/')\n",
    "args = parser.parse_args()\n",
    "# early_stopping = EarlyStopping(monitor='loss', patience=1000)\n",
    "key = args.dataset.split('/')[-1].split('_')[0]\n",
    "spath = args.output + key + '_' + str(args.numTrain) + '/'\n",
    "os.makedirs(spath, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据，并分配好雷达数据和高光谱数据\n",
    "hsi = np.load(args.dataset).astype('float32')\n",
    "print()\n",
    "gt = np.load(args.gt).astype('int')\n",
    "num_classes = np.max(gt)\n",
    "row, col, layers = hsi.shape\n",
    "c1 = rscls.rscls(hsi, gt, cls=num_classes)\n",
    "c1.padding(9)\n",
    "x1_train, y1_train = c1.train_sample(args.numTrain) \n",
    "x1_train, y1_train = rscls.make_sample(x1_train, y1_train) \n",
    "x1_lidar_train = x1_train[:, :, :, -1]\n",
    "x1_lidar_train = x1_lidar_train[:, :, :, np.newaxis]\n",
    "x1_train = x1_train[:, :, :, :-1]\n",
    "y1_train = to_categorical(y1_train, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看当前的输出的形状\n",
    "\n",
    "# 写一个Dataset类\n",
    "train_dataset = CustomDataset(torch.tensor(x1_train), torch.tensor(x1_lidar_train),torch.tensor(y1_train))\n",
    "# 写一个data_loader\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNet99(layers - 1, 1, 9, num_classes).to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "criterion2 = nn.L1Loss()\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for epoch in tqdm(range(args.num_epochs1 + args.num_epochs2)):\n",
    "# for epoch in range(args.num_epochs1 + args.num_epochs1):\n",
    "    model.train()                                # 用于将模型设置为训练模式\n",
    "    for x, x_lidar, y in train_data_loader:\n",
    "        x = x.permute(0,3,1,2)\n",
    "        x_lidar = x_lidar.permute(0,3,1,2)\n",
    "        x = torch.FloatTensor(x).to(device)  # 确保x是float\n",
    "        x_lidar = torch.FloatTensor(x_lidar).to(device)  # 确保x_lidar是float\n",
    "        \n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output1, output2 = model(x,x_lidar)  # 假设你的模型接受一个输入\n",
    "        y = y.float()\n",
    "        # output1 = output1.float()\n",
    "        loss1 = criterion1(output1,torch.argmax(y,dim=1))\n",
    "        loss2 = criterion2(output2,x)\n",
    "        loss = 0.5 * loss1 + 0.5 * loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()  # 在每个epoch结束时调\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "print('Model saved to model.pth')\n",
    "\n",
    "end_time = time.time()\n",
    "print('Training time:', end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time3 = int(time.time())\n",
    "print('Start predicting...')\n",
    "pre_all = []\n",
    "pre_loss = []\n",
    "for r in tqdm(range(row)):\n",
    "    row_samples = c1.all_sample_row(r)\n",
    "    pre_row, recons = model([row_samples[:, :, :, :-1], (row_samples[:, :, :, -1])[:, :, :, np.newaxis]])\n",
    "    pre_all.append(pre_row)\n",
    "    recons_loss = dist(recons.reshape(col, -1), row_samples[:, :, :, :-1].reshape(col, -1))\n",
    "    pre_loss.append(recons_loss)\n",
    "pre_all = np.array(pre_all).astype('float64')\n",
    "pre_loss = np.array(pre_loss).reshape(-1).astype('float64')\n",
    "recons_train = model([x1_train, x1_lidar_train])[1]\n",
    "train_loss = dist(recons_train.reshape(recons_train.shape[0], -1), x1_train.reshape(x1_train.shape[0], -1))\n",
    "\n",
    "time4 = int(time.time())\n",
    "print('predict time:',time4-time3)\n",
    "\n",
    "print('Start caculating open-set...')\n",
    "mr = libmr.MR()\n",
    "mr.fit_high(train_loss, 20)\n",
    "wscore = mr.w_score_vector(pre_loss)\n",
    "mask = wscore > 0.5 \n",
    "mask = mask.reshape(row, col)\n",
    "unknown = gt.max() + 1\n",
    "\n",
    "# for close set\n",
    "pre_closed = np.argmax(pre_all, axis=-1) + 1 \n",
    "imgDraw(pre_closed, spath + key + '_closed', path='./', show=False)\n",
    "\n",
    "# for open set\n",
    "pre_gsrl = deepcopy(pre_closed)\n",
    "pre_gsrl[mask == 1] = unknown \n",
    "gt_new = deepcopy(gt)\n",
    "\n",
    "gt2file = glob.glob('data/Trento/' + key + '*gt*[0-9].npy')[0]\n",
    "# gt2file = glob.glob('data/Houston/' + key + '*gt*[0-9].npy')[0]\n",
    "\n",
    "gt2 = np.load(gt2file)\n",
    "gt_new[np.logical_and(gt_new == 0, gt2 != 0)] = unknown\n",
    "cfm = rscls.gtcfm(pre_gsrl, gt_new, unknown)\n",
    "\n",
    "pre_to_draw = deepcopy(pre_gsrl)\n",
    "pre_to_draw[pre_to_draw == unknown] = 0\n",
    "imgDraw(pre_to_draw, spath + key + '_gsrl', path='./', show=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
